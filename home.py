import streamlit as st
import numpy as np
import os
os.environ['KERAS_BACKEND'] = 'tensorflow'
import tensorflow as tf
import matplotlib.pyplot as plt 
import keras
from PIL import Image
import io
import matplotlib


st.set_page_config(page_title="ê·€ ì§ˆí™˜ ì§„ë‹¨ ì„œë¹„ìŠ¤", page_icon="ğŸ“¸")

st.image('./image/main.png', use_column_width=True)

st.markdown('''
<style>
    .big-header {
        text-align: center;
        padding: 30px 0;
        margin-bottom: 10px;
        border-bottom: 3px solid #ffd700;
    }
    .result {
        font-size: 20px; /* ê²°ê³¼ í…ìŠ¤íŠ¸ í¬ê¸° ì„¤ì • */
    }
    .result2 {
        font-size: 15px; /* ì‘ì€ ê¸€ê¼´ í¬ê¸° ì„¤ì • */
        text-align: center;
        padding: 20px 0;
        margin-bottom: 10px;
        border-top: 3px solid #ffd700;
    }
            
    [data-testid="StyledFullScreenButton"]{
            visibility: hidden
    }
                    
</style>
''', unsafe_allow_html=True)


st.markdown('''
ğŸ“Œ ê°€ì •ìš© ê·€ ë‚´ì‹œê²½ì„ í†µí•´ **ì§ì ‘** ì°ì€ ì‚¬ì§„ì— ëŒ€í•´ **ì •ìƒ/ë¹„ì •ìƒ ìœ ë¬´ ë° í™•ë¥ **ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.
''')

st.markdown('''
ğŸ“Œ **ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ**í•˜ê±°ë‚˜ **ì˜ˆì‹œ ì´ë¯¸ì§€ë¥¼ ì„ íƒ**í•´ ì£¼ì„¸ìš”.
''')



def recall(y_true, y_pred):
    true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))
    possible_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + keras.backend.epsilon())
    return recall

def precision(y_true, y_pred):
    true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))
    predicted_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + keras.backend.epsilon())
    return precision

def f1(y_true, y_pred):
    precisionx = precision(y_true, y_pred)
    recallx = recall(y_true, y_pred)
    return 2*((precisionx*recallx)/(precisionx+recallx+keras.backend.epsilon()))

# @st.cache_resource -> ì‚¬ìš©í•´ì„œ inference time 15ì´ˆì—ì„œ 5ì´ˆì •ë„ë¡œ ê°ì†Œ
@st.cache_resource  
def load_model(model_path):
    return tf.keras.models.load_model(model_path, custom_objects={'precision': precision, 'recall': recall, 'f1': f1})


def predict_image(model, img_array):
    return model.predict(img_array)

def inference_crop(img_path, model, img_height=299, img_width=299):
    img_ori = tf.keras.preprocessing.image.load_img(img_path)
    img = tf.image.resize(img_ori, [img_height, img_width])
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = img_array / 255

    predictions = predict_image(model, img_array)  # ëª¨ë¸ ì˜ˆì¸¡ í˜¸ì¶œ

    # í´ë˜ìŠ¤ ë° í´ë˜ìŠ¤ í™•ë¥  ì¶œë ¥
    class_labels = ["Abnormal", "Normal"]  # í´ë˜ìŠ¤ ë¼ë²¨ ì„¤ì •
    predicted_class = np.argmax(predictions)
    predicted_class_label = class_labels[predicted_class]
    Abnormal_probability = predictions[0][0]
    normal_probability = predictions[0][1]

    if predicted_class_label == "Abnormal":
        prob = Abnormal_probability
    else:
        prob = normal_probability

    return img_path, predicted_class_label, prob

###############################################################################################


def show_heatmap(image_path, model):
    original_image = Image.open(image_path)
    if original_image.mode == 'RGBA':
        original_image = original_image.convert('RGB')  # ì•ŒíŒŒ ì±„ë„ ì œê±°
    cropped = tf.image.central_crop(original_image, central_fraction=0.8)
    encoded_image = tf.image.encode_png(cropped)

    # EagerTensorë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
    encoded_image_np = encoded_image.numpy()
    cropped_img_410 = Image.open(io.BytesIO(encoded_image_np))
    cropped_img = cropped_img_410.resize((299, 299))

    # tf.keras.preprocessing.image
    x = tf.keras.preprocessing.image.img_to_array(cropped_img)
    x = np.expand_dims(x, axis=0)
    # ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê¸° ì „ì— ë³µì‚¬í•˜ì—¬ ìƒˆë¡œìš´ ë°°ì—´ì„ ìƒì„±
    x = x.copy()
    x = tf.keras.applications.xception.preprocess_input(x)

    last_conv_layer = model.get_layer("block14_sepconv2_act")
    model_1 = tf.keras.Model(model.inputs, last_conv_layer.output)

    input_2 = tf.keras.Input(shape=last_conv_layer.output.shape[1:])
    x_2 = model.get_layer("global_average_pooling2d_1")(input_2)
    x_2 = model.get_layer("dense_2")(x_2)
    x_2 = model.get_layer("dense_3")(x_2)
    model_2 = tf.keras.Model(input_2, x_2)

    with tf.GradientTape() as tape:
        output_1 = model_1(x)
        tape.watch(output_1)  # ë§ˆì§€ë§‰ ì¸µìœ¼ë¡œ ë¯¸ë¶„í•˜ê¸° ìœ„í•œ ì¤€ë¹„
        preds = model_2(output_1)
        class_id = tf.argmax(preds[0])
        output_2 = preds[:, class_id]

    grads = tape.gradient(output_1, output_1)  # ê·¸ë ˆë””ì–¸íŠ¸ ê³„ì‚°
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))  # ì‹5 ì ìš©

    output_1 = output_1.numpy()[0]
    pooled_grads = pooled_grads.numpy()
    for i in range(pooled_grads.shape[-1]):
        output_1[:, :, i] *= pooled_grads[i]

    heatmap = np.mean(output_1, axis=-1)
    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)  # ì •ê·œí™”

    img = tf.keras.preprocessing.image.load_img(image_path)
    if img.mode == 'RGBA':
        img = img.convert('RGB')  # ì•ŒíŒŒ ì±„ë„ ì œê±°
    img = tf.keras.preprocessing.image.img_to_array(img)
    img_tensor = tf.convert_to_tensor(img)

    cropped = tf.image.central_crop(img_tensor, central_fraction=0.8)
    cropped_img = cropped.numpy().astype(np.uint8)

    heatmap = np.uint8(255 * heatmap)  # [0,255]ë¡œ ë³€í™˜

    jet = matplotlib.colormaps.get_cmap("jet")  # jet ì»¬ëŸ¬ë§µìœ¼ë¡œ í‘œì‹œ
    color = jet(np.arange(256))[:, :3]
    color_heatmap = color[heatmap]

    color_heatmap = tf.keras.preprocessing.image.array_to_img(color_heatmap)
    color_heatmap = color_heatmap.resize((cropped_img.shape[1], cropped_img.shape[0]))
    color_heatmap = tf.keras.preprocessing.image.img_to_array(color_heatmap)

    overlay_img = color_heatmap * 0.4 + cropped_img  # ë§ì”Œì›€
    overlay_img = tf.keras.preprocessing.image.array_to_img(overlay_img)

    # ìˆ˜ì • ì‹œë„
    color_heatmap = tf.keras.preprocessing.image.array_to_img(color_heatmap)

    return color_heatmap, overlay_img


best_model = load_model("./model/crop_model.h5")


# ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
default_image_path1 = "./image/otitexterna_27.png" 
default_image_path2 = "./image/ì •ìƒ_1.png"


with st.spinner("### â³ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):


    col1, col2 = st.columns(2)
    with col1:
        use_default_image1 = st.toggle("ì˜ˆì‹œ ì´ë¯¸ì§€(ì™¸ì´ë„ì—¼)", value=False)
    with col2:
        use_default_image2 = st.toggle("ì˜ˆì‹œ ì´ë¯¸ì§€(ì •ìƒ)", value=False)

    # íŒŒì¼ ì—…ë¡œë”
    uploaded_file = st.file_uploader("ğŸ“¸ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì‹œê¸¸ ë°”ëë‹ˆë‹¤!", type=['png', 'jpg', 'jpeg'])

    # ì´ë¯¸ì§€ ë¡œë“œ
    if uploaded_file is not None: # ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•œ ê²½ìš°
        image = Image.open(uploaded_file)
        st.image(image, caption='Uploaded Image.', use_column_width=True)

        # ëª¨ë¸ inference -> label ë° í™•ë¥  ì¶œë ¥
        path, label, prob = inference_crop(uploaded_file, best_model)
        # íˆíŠ¸ë§µ, íˆíŠ¸ë§µ+ì›ë³¸ ì¶œë ¥
        hm, overlay = show_heatmap(uploaded_file, best_model)
        
        if label == 'Normal':
            emoji = 'ğŸ™‚'
            color = '#0000FF'
            label_kor = 'ì •ìƒ'
        else:
            emoji = 'ğŸ˜«'
            color = '#FF0000'
            label_kor = 'ë¹„ì •ìƒ'

        st.markdown(f'''
        <div class="header">
            <h2><span style="color: {color};">{label_kor}{emoji}ìœ¼ë¡œ íŒë³„ë˜ì—ˆìŠµë‹ˆë‹¤.</span></h2>
            <h2 class='result'><span style="color: {color};">{label_kor}ì¼ í™•ë¥ ì´ {prob:.4f}ì…ë‹ˆë‹¤.</span></h2>
        </div>
        ''', unsafe_allow_html=True)
        
    elif use_default_image1 and not(use_default_image2): # ì˜ˆì‹œ ì´ë¯¸ì§€1ì„ ì„ íƒí•œ ê²½ìš°
        image = Image.open(default_image_path1)
        st.image(image, caption='Default Image1.', use_column_width=True)

        path, label, prob = inference_crop(default_image_path1, best_model)
        hm, overlay = show_heatmap(default_image_path1, best_model)
        
        if label == 'Normal':
            emoji = 'ğŸ™‚'
            color = '#0000FF'
            label_kor = 'ì •ìƒ'
        else:
            emoji = 'ğŸ˜«'
            color = '#FF0000'
            label_kor = 'ë¹„ì •ìƒ'

        st.markdown(f'''
        <div class="header">
            <h2><span style="color: {color};">{label_kor}{emoji}ìœ¼ë¡œ íŒë³„ë˜ì—ˆìŠµë‹ˆë‹¤.</span></h2>
            <h2 class='result'><span style="color: {color};">{label_kor}ì¼ í™•ë¥ ì´ {prob:.4f}ì…ë‹ˆë‹¤.</span></h2>
        </div>
        ''', unsafe_allow_html=True)


        
    elif use_default_image2 and not(use_default_image1): # ì˜ˆì‹œ ì´ë¯¸ì§€2ë¥¼ ì„ íƒí•œ ê²½ìš°
        image = Image.open(default_image_path2)
        st.image(image, caption='Default Image2.', use_column_width=True)    

        path, label, prob = inference_crop(default_image_path2, best_model)
        hm, overlay = show_heatmap(default_image_path2, best_model)
        
        if label == 'Normal':
            emoji = 'ğŸ™‚'
            color = '#0000FF'
            label_kor = 'ì •ìƒ'
        else:
            emoji = 'ğŸ˜«'
            color = '#FF0000'
            label_kor = 'ë¹„ì •ìƒ'

        st.markdown(f'''
        <div class="header">
            <h2><span style="color: {color};">{label_kor}{emoji}ìœ¼ë¡œ íŒë³„ë˜ì—ˆìŠµë‹ˆë‹¤.</span></h2>
            <h2 class='result'><span style="color: {color};">{label_kor}ì¼ í™•ë¥ ì´ {prob:.4f}ì…ë‹ˆë‹¤.</span></h2>
        </div>
        ''', unsafe_allow_html=True)    



    if (uploaded_file and not use_default_image1 and not use_default_image2) or \
    (not uploaded_file and use_default_image1 and not use_default_image2) or \
    (not uploaded_file and not use_default_image1 and use_default_image2):
        with st.expander("ğŸ” ëª¨ë¸ì´ ì–´ëŠ ë¶€ë¶„ì„ ë³´ê³  íŠ¹ì • í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•˜ì˜€ëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•´ë³´ì•„ìš”!", expanded=True):

            col1, col2 = st.columns([4.5, 4.5])
            with col1: # íˆíŠ¸ë§µ ì´ë¯¸ì§€ ë“¤ì–´ê°ˆ ê³³
                image = Image.open(default_image_path1)
                st.image(hm, caption='Heatmap', use_column_width=True)
                
            with col2: # ì›ë³¸ + íˆíŠ¸ë§µ ì´ë¯¸ì§€ ë“¤ì–´ê°ˆ ê³³
                image = Image.open(default_image_path2)
                st.image(overlay, caption='Overlapped Image', use_column_width=True)

            # with col3:
            #     st.image('./image/color_bar.png', caption='', use_column_width=True)
                

            st.image('./image/color_bar_ê°€ë¡œ.png', caption='', use_column_width=True)

            st.markdown('''
                â— **ë¹¨ê°„ ë¶€ë¶„**ì¼ìˆ˜ë¡, ëª¨ë¸ì´ íŒë‹¨ì˜ ê·¼ê±°ë¡œì¨ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•œ ë¶€ë¶„ì…ë‹ˆë‹¤.
            ''')            



st.markdown('''
<div>
    <h2 class='result2'><span style="color:#000000	;">CLEAR(ê°•í•˜ëŒ, ê¹€ê¸°ë‚¨, ì¢ŒëŒ€í˜„)</span></h2>
</div>
''', unsafe_allow_html=True)